# ğŸ”¬ ArXiv RAG Bot

An AI-powered question-answering bot for ArXiv research papers, built with RAG (Retrieval-Augmented Generation), FAISS vector search, and local LLMs via Ollama.

## ğŸš€ Demo

Load any ArXiv paper by ID and ask questions about it in natural language. The bot retrieves the most relevant sections and generates detailed answers using a local language model.

## ğŸ› ï¸ Tech Stack

- **LangChain** â€” RAG pipeline orchestration
- **FAISS** â€” Vector similarity search
- **Ollama** â€” Local LLM inference (Mistral, LLaMA, Aya)
- **Streamlit** â€” Web interface
- **nomic-embed-text** â€” Text embeddings

## âš™ï¸ Installation

### Prerequisites
- Python 3.10+
- [Ollama](https://ollama.com) installed and running

### Setup
```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/arxiv-rag-bot.git
cd arxiv-rag-bot

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Pull required models
```bash
ollama pull mistral
ollama pull nomic-embed-text
```

### Run
```bash
streamlit run app.py
```

## ğŸ“– How It Works

1. **Load** â€” Enter an ArXiv paper ID to download and index the PDF
2. **Chunk** â€” The paper is split into overlapping chunks of text
3. **Embed** â€” Each chunk is converted to a vector using nomic-embed-text
4. **Retrieve** â€” When you ask a question, FAISS finds the most similar chunks
5. **Generate** â€” Mistral generates a detailed answer based on the retrieved chunks

## ğŸ’¡ Example Usage

Load paper `1706.03762` (Attention Is All You Need) and ask:
- *What is the purpose of the attention mechanism?*
- *How does the Transformer architecture work?*
- *What are the main experimental results?*

## ğŸ“ Project Structure
```
arxiv-rag-bot/
â”œâ”€â”€ app.py          # Streamlit web interface
â”œâ”€â”€ ingest.py       # PDF download and vector store creation
â”œâ”€â”€ rag.py          # RAG pipeline and question answering
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```